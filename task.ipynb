{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikitamaia/tensorflow-examples/blob/main/task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FROM PROTOTYPE TO PRODUCTION\n",
        "#### Train an image classification model on the [flower photos dataset](https://www.tensorflow.org/datasets/catalog/tf_flowers). \n",
        "\n",
        "## ðŸŒ¹ ðŸŒ¸ ðŸŒº ðŸŒ¼ ðŸŒ»"
      ],
      "metadata": {
        "id": "SsH96zko_CT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is part of the From Prototype to Production video series, which covers the basics of training, scaling, and deploying custom models on Google Cloud."
      ],
      "metadata": {
        "id": "ZAjrQgKPAcfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries"
      ],
      "metadata": {
        "id": "OCMkt3Ii-8lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "s7DZwX_pAzqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define variables"
      ],
      "metadata": {
        "id": "0mviTdX1A1DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 5\n",
        "EPOCHS=10\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "IMG_HEIGHT = 180\n",
        "IMG_WIDTH = 180"
      ],
      "metadata": {
        "id": "IO_rzBBGA0Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the data"
      ],
      "metadata": {
        "id": "fXKIezXQAuwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4FQ0QXtACXY",
        "outputId": "07fa10f2-84ac-4597-9ebe-6aabb67def64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 10s 0us/step\n",
            "228827136/228813984 [==============================] - 10s 0us/step\n"
          ]
        }
      ],
      "source": [
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify that images have been downloaded by printing the image count."
      ],
      "metadata": {
        "id": "k1W0BSVVAqB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "id": "DrY3ZWvoA5Ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e766626e-a6eb-4e89-c9cb-193263e4590c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define `create_datasets` function, which uses the [`tf.keras.utils.image_dataset_from_directory` utility](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) to load the images off disk into a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)."
      ],
      "metadata": {
        "id": "yG3hWzsmBskO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_datasets(data_dir, batch_size):\n",
        "  train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size)\n",
        "  \n",
        "  validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=batch_size)\n",
        "\n",
        "  train_dataset = train_dataset.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  validation_dataset = validation_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "  return train_dataset, validation_dataset"
      ],
      "metadata": {
        "id": "P0OJP2KJEfa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define `create_model` function which creates our image classification model using the [`tf.keras` Sequential API](https://www.tensorflow.org/guide/keras/sequential_model)."
      ],
      "metadata": {
        "id": "4u_9-WueDvhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Resizing(IMG_HEIGHT, IMG_WIDTH),\n",
        "    tf.keras.layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "37INOWzpDpzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the training and validation datasets"
      ],
      "metadata": {
        "id": "wtM29RPTTeAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, validation_dataset = create_datasets(data_dir, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "5PS4-clkTaGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b785128-d46a-45d3-bf13-530a60445e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3670 files belonging to 5 classes.\n",
            "Using 2936 files for training.\n",
            "Found 3670 files belonging to 5 classes.\n",
            "Using 734 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and compile the model"
      ],
      "metadata": {
        "id": "mfi1Nm2cThck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZfxQ-bQYD32j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the model"
      ],
      "metadata": {
        "id": "kVWfptZXTkZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "  train_dataset,\n",
        "  validation_data=validation_dataset,\n",
        "  epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uxk95wYo18M",
        "outputId": "8e5228d4-bc8c-4fc6-8333-ba7a2f039cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "92/92 [==============================] - 103s 1s/step - loss: 1.3148 - accuracy: 0.4407 - val_loss: 1.0995 - val_accuracy: 0.5518\n",
            "Epoch 2/10\n",
            "92/92 [==============================] - 95s 1s/step - loss: 0.9906 - accuracy: 0.6196 - val_loss: 0.9941 - val_accuracy: 0.6240\n",
            "Epoch 3/10\n",
            "92/92 [==============================] - 96s 1s/step - loss: 0.8238 - accuracy: 0.6866 - val_loss: 0.9361 - val_accuracy: 0.6458\n",
            "Epoch 4/10\n",
            "92/92 [==============================] - 95s 1s/step - loss: 0.6113 - accuracy: 0.7800 - val_loss: 0.9760 - val_accuracy: 0.6417\n",
            "Epoch 5/10\n",
            "92/92 [==============================] - 96s 1s/step - loss: 0.3852 - accuracy: 0.8651 - val_loss: 1.0474 - val_accuracy: 0.6417\n",
            "Epoch 6/10\n",
            "92/92 [==============================] - 95s 1s/step - loss: 0.2125 - accuracy: 0.9305 - val_loss: 1.2383 - val_accuracy: 0.6294\n",
            "Epoch 7/10\n",
            "92/92 [==============================] - 97s 1s/step - loss: 0.1334 - accuracy: 0.9561 - val_loss: 1.4411 - val_accuracy: 0.6267\n",
            "Epoch 8/10\n",
            "92/92 [==============================] - 95s 1s/step - loss: 0.0622 - accuracy: 0.9843 - val_loss: 1.8252 - val_accuracy: 0.6403\n",
            "Epoch 9/10\n",
            "92/92 [==============================] - 96s 1s/step - loss: 0.0559 - accuracy: 0.9850 - val_loss: 2.0074 - val_accuracy: 0.6308\n",
            "Epoch 10/10\n",
            "92/92 [==============================] - 96s 1s/step - loss: 0.0491 - accuracy: 0.9925 - val_loss: 2.0396 - val_accuracy: 0.6512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model"
      ],
      "metadata": {
        "id": "lm7kWnSWTmfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model-output')"
      ],
      "metadata": {
        "id": "vf6LXvknEGAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7073e76-0f3d-48e5-cdb8-04c8a25c9040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model-output/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LTdnQPiVtwZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}